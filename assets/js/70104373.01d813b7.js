"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[468],{2155:(e,s,a)=>{a.d(s,{Al:()=>g});var n=a(6540),o=a(382),t=a(5164),r=a(1876),i=a(1028),l=a(8532),c=a(797);const d={chatContainer:"chatContainer_n01S",chatHeader:"chatHeader__q4e",modelInfo:"modelInfo_VI07",modelName:"modelName_aopu",chatDate:"chatDate_UKB_",messagesContainer:"messagesContainer_DpfC",messageRow:"messageRow_IrVw",userMessageRow:"userMessageRow_MRjs",userAvatar:"userAvatar_lmu6",assistantAvatar:"assistantAvatar_F2Ic",userMessage:"userMessage_YQgg",assistantMessage:"assistantMessage_Scqo",chatHeading:"chatHeading_lXc1",loading:"loading_R2yl",error:"error_KRlI"};var m=a(4848);function h(e){let{children:s}=e;return"string"==typeof s?(0,m.jsx)(t.$,{rehypePlugins:[r.A],remarkPlugins:[i.A],components:{h1:e=>{let{node:s,...a}=e;return(0,m.jsx)("h1",{className:d.chatHeading,...a})},h2:e=>{let{node:s,...a}=e;return(0,m.jsx)("h2",{className:d.chatHeading,...a})},h3:e=>{let{node:s,...a}=e;return(0,m.jsx)("h3",{className:d.chatHeading,...a})},h4:e=>{let{node:s,...a}=e;return(0,m.jsx)("h4",{className:d.chatHeading,...a})},h5:e=>{let{node:s,...a}=e;return(0,m.jsx)("h5",{className:d.chatHeading,...a})},h6:e=>{let{node:s,...a}=e;return(0,m.jsx)("h6",{className:d.chatHeading,...a})}},children:s}):(0,m.jsx)(m.Fragment,{children:s})}function u(e){let{children:s}=e;return(0,m.jsxs)("div",{className:d.userMessageRow,children:[(0,m.jsx)("div",{className:d.userAvatar,children:(0,m.jsx)("span",{children:"\ud83d\udc64"})}),(0,m.jsx)("div",{className:d.userMessage,children:(0,m.jsx)(h,{children:s})})]})}function p(e){let{children:s}=e;return(0,m.jsxs)("div",{className:d.messageRow,children:[(0,m.jsx)("div",{className:d.assistantAvatar,children:(0,m.jsx)("span",{children:"\ud83e\udd16"})}),(0,m.jsx)("div",{className:d.assistantMessage,children:(0,m.jsx)(h,{children:s})})]})}function g(e){let{children:s,model:a="Asistente IA",date:t="",source:r}=e;const[i,h]=(0,n.useState)([]),[g,j]=(0,n.useState)(a),[x,f]=(0,n.useState)(t),[v,N]=(0,n.useState)(Boolean(r)),[b,w]=(0,n.useState)(null),{siteConfig:_}=(0,c.A)(),{colorMode:A}=(0,l.G)();return(0,n.useEffect)((()=>{r&&async function(){try{const e=r.startsWith("http")?r:`${_.baseUrl||""}${r.startsWith("/")?r:`/${r}`}`,s=await fetch(e);if(!s.ok)throw new Error(`Failed to load conversation: ${s.status}`);const a=await s.text(),n=o.Ay.load(a);if(n.model&&j(n.model),n.date&&f(n.date),!Array.isArray(n.messages))throw new Error("Invalid conversation format: messages should be an array");h(n.messages)}catch(e){const s=e instanceof Error?e.message:"Unknown error";w(s),console.error("Error loading conversation:",e)}finally{N(!1)}}()}),[r,_.baseUrl]),v?(0,m.jsx)("div",{className:d.loading,children:"Loading conversation..."}):b?(0,m.jsxs)("div",{className:d.error,children:["Error: ",b]}):(0,m.jsxs)("div",{className:d.chatContainer,children:[(0,m.jsx)("div",{className:d.chatHeader,children:(0,m.jsxs)("div",{className:d.modelInfo,children:[(0,m.jsx)("span",{className:d.modelName,children:g}),(0,m.jsx)("span",{className:d.chatDate,children:x})]})}),(0,m.jsx)("div",{className:d.messagesContainer,children:i.length>0?i.map(((e,s)=>"user"===e.role?(0,m.jsx)(u,{children:e.content},s):(0,m.jsx)(p,{children:e.content},s))):s})]})}},7833:(e,s,a)=>{a.r(s),a.d(s,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"ejemplos/pensamiento-paso-a-paso","title":"Pensamiento paso a paso","description":"La estrategia de Chain of Thought (CoT) consiste en pedir al modelo expl\xedcitamente que realice una serie de pasos l\xf3gicos para resolver un problema. Sin embargo, actualmente casi todos los modelos de IA lo hacen de manera impl\xedcita (modelos con razonamiento).","source":"@site/docs/31-ejemplos/03-pensamiento-paso-a-paso.mdx","sourceDirName":"31-ejemplos","slug":"/ejemplos/pensamiento-paso-a-paso","permalink":"/ia-educacion/docs/ejemplos/pensamiento-paso-a-paso","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Instrucciones espec\xedficas","permalink":"/ia-educacion/docs/ejemplos/instrucciones-especificas"},"next":{"title":"Uso de ejemplos de respuesta","permalink":"/ia-educacion/docs/ejemplos/ejemplos"}}');var o=a(4848),t=a(8453),r=a(2155);const i={},l="Pensamiento paso a paso",c={},d=[];function m(e){const s={blockquote:"blockquote",em:"em",h1:"h1",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(s.header,{children:(0,o.jsx)(s.h1,{id:"pensamiento-paso-a-paso",children:"Pensamiento paso a paso"})}),"\n",(0,o.jsxs)(s.p,{children:["La estrategia de ",(0,o.jsx)(s.em,{children:"Chain of Thought"})," (CoT) consiste en pedir al modelo expl\xedcitamente que realice una serie de pasos l\xf3gicos para resolver un problema. Sin embargo, actualmente casi todos los modelos de IA lo hacen de manera impl\xedcita (modelos con razonamiento)."]}),"\n",(0,o.jsx)(r.Al,{source:"/data/chats/chain-of-thought.yaml"}),"\n",(0,o.jsxs)(s.blockquote,{children:["\n",(0,o.jsxs)(s.p,{children:[(0,o.jsx)(s.strong,{children:"Por qu\xe9 funciona"}),":"]}),"\n",(0,o.jsxs)(s.ul,{children:["\n",(0,o.jsx)(s.li,{children:"Indica el formato de respuesta (explicaci\xf3n paso a paso)."}),"\n",(0,o.jsx)(s.li,{children:"Da un problema claro."}),"\n",(0,o.jsx)(s.li,{children:"Obliga al modelo a mostrar su proceso de pensamiento."}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,t.R)(),...e.components};return s?(0,o.jsx)(s,{...e,children:(0,o.jsx)(m,{...e})}):m(e)}}}]);